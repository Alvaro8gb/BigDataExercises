{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.ml.feature as feature\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import when, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/04 17:05:47 WARN Utils: Your hostname, alvaro-ThinkPad-X1-Carbon-Gen-10 resolves to a loopback address: 127.0.1.1; using 192.168.1.130 instead (on interface wlp0s20f3)\n",
      "24/01/04 17:05:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/04 17:05:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlightAnalysisApp\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=====>                                                    (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2389217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DATA_2008 = \"../ds/bigData/flight-2008.csv.bz2\"\n",
    "#DATA_1990 = \"../ds/flight-1990.csv.bz2\"\n",
    "flights_df = spark.read.csv(DATA_2008, header=True, inferSchema=True)\n",
    "print(flights_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2008|    1|         3|        4|   1703|      1645|     33|        35|           WN|      767| N222WN|              270|           290|    257|      -2|      18|   LAS| MHT|    2356|     4|      9|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1630|      1600|     23|      2350|           WN|      416| N401WN|              293|           290|    266|      33|      30|   LAS| PVD|    2363|     4|     23|        0|            NULL|       0|           6|           0|       3|            0|               24|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with only the first 1000 instances\n",
    "flights_subset_df = flights_df.sample(withReplacement=False, fraction=10000/flights_df.count(), seed=42)\n",
    "\n",
    "flights_subset_df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=====>                                                   (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset DataFrame Count: 10043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display the number of rows in the subset DataFrame\n",
    "print(\"Subset DataFrame Count:\", flights_subset_df.count())\n",
    "\n",
    "output_path = \"../ds/samples/sample_10000\"\n",
    "\n",
    "#flights_subset_df.write.csv(output_path,compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1703</td>\n",
       "      <td>1645</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>WN</td>\n",
       "      <td>767</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1630</td>\n",
       "      <td>1600</td>\n",
       "      <td>23</td>\n",
       "      <td>2350</td>\n",
       "      <td>WN</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>737</td>\n",
       "      <td>735</td>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "      <td>WN</td>\n",
       "      <td>547</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1138</td>\n",
       "      <td>1110</td>\n",
       "      <td>1252</td>\n",
       "      <td>1250</td>\n",
       "      <td>WN</td>\n",
       "      <td>2463</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1824</td>\n",
       "      <td>1815</td>\n",
       "      <td>1938</td>\n",
       "      <td>1935</td>\n",
       "      <td>WN</td>\n",
       "      <td>2034</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek DepTime  CRSDepTime ArrTime  CRSArrTime  \\\n",
       "0  2008      1           3          4    1703        1645      33          35   \n",
       "1  2008      1           3          4    1630        1600      23        2350   \n",
       "2  2008      1           3          4     737         735     855         855   \n",
       "3  2008      1           3          4    1138        1110    1252        1250   \n",
       "4  2008      1           3          4    1824        1815    1938        1935   \n",
       "\n",
       "  UniqueCarrier  FlightNum  ... TaxiIn TaxiOut Cancelled CancellationCode  \\\n",
       "0            WN        767  ...      4       9         0             None   \n",
       "1            WN        416  ...      4      23         0             None   \n",
       "2            WN        547  ...      4       8         0             None   \n",
       "3            WN       2463  ...      2      12         0             None   \n",
       "4            WN       2034  ...      4      13         0             None   \n",
       "\n",
       "  Diverted CarrierDelay WeatherDelay NASDelay  SecurityDelay LateAircraftDelay  \n",
       "0        0           NA           NA       NA             NA                NA  \n",
       "1        0            6            0        3              0                24  \n",
       "2        0           NA           NA       NA             NA                NA  \n",
       "3        0           NA           NA       NA             NA                NA  \n",
       "4        0           NA           NA       NA             NA                NA  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = flights_subset_df.toPandas()\n",
    "\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.to_csv(output_path + '.bz2', index=False, compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2008|    1|         3|        4|   1343|      1325|   1451|      1435|           WN|      588| N240WN|               68|            70|     55|      16|      18|   HOU| LIT|     393|     4|      9|        0|            NULL|       0|          16|           0|       0|            0|                0|\n",
      "|2008|    1|         3|        4|   1125|      1120|   1247|      1245|           WN|     1343| N523SW|               82|            85|     71|       2|       5|   HOU| MAF|     441|     3|      8|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   2009|      2015|   2136|      2140|           WN|     3841| N280WN|               87|            85|     71|      -4|      -6|   HOU| MAF|     441|     2|     14|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|    903|       855|   1203|      1205|           WN|        3| N308SA|              120|           130|    108|      -2|       8|   HOU| MCO|     848|     5|      7|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1423|      1400|   1726|      1710|           WN|       25| N462WN|              123|           130|    107|      16|      23|   HOU| MCO|     848|     6|     10|        0|            NULL|       0|          16|           0|       0|            0|                0|\n",
      "|2008|    1|         3|        4|   2024|      2020|   2325|      2325|           WN|       51| N483WN|              121|           125|    101|       0|       4|   HOU| MCO|     848|    13|      7|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1753|      1745|   2053|      2050|           WN|      940| N493WN|              120|           125|    107|       3|       8|   HOU| MCO|     848|     6|      7|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|    622|       620|    935|       930|           WN|     2621| N266WN|              133|           130|    107|       5|       2|   HOU| MCO|     848|     7|     19|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1944|      1945|   2210|      2215|           WN|      389| N266WN|              146|           150|    124|      -5|      -1|   HOU| MDW|     937|     7|     15|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1453|      1425|   1716|      1650|           WN|      519| N514SW|              143|           145|    124|      26|      28|   HOU| MDW|     937|     6|     13|        0|            NULL|       0|          11|           0|       0|            0|               15|\n",
      "|2008|    1|         3|        4|   2030|      2015|   2251|      2245|           WN|      894| N716SW|              141|           150|    122|       6|      15|   HOU| MDW|     937|    11|      8|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|    708|       615|    936|       840|           WN|      969| N215WN|              148|           145|    128|      56|      53|   HOU| MDW|     937|    10|     10|        0|            NULL|       0|          53|           0|       3|            0|                0|\n",
      "|2008|    1|         3|        4|   1749|      1730|   2039|      2000|           WN|     2174| N623SW|              170|           150|    128|      39|      19|   HOU| MDW|     937|    34|      8|        0|            NULL|       0|          10|           0|      20|            0|                9|\n",
      "|2008|    1|         3|        4|   1217|      1215|   1431|      1440|           WN|     2445| N651SW|              134|           145|    124|      -9|       2|   HOU| MDW|     937|     4|      6|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|    954|       940|   1206|      1205|           WN|     2974| N447WN|              132|           145|    120|       1|      14|   HOU| MDW|     937|     5|      7|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1758|      1800|   1854|      1900|           WN|       41| N240WN|               56|            60|     45|      -6|      -2|   HOU| MSY|     303|     3|      8|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   2210|      2120|   2305|      2215|           WN|       78| N268WN|               55|            55|     44|      50|      50|   HOU| MSY|     303|     3|      8|        0|            NULL|       0|           6|           0|       0|            0|               44|\n",
      "|2008|    1|         3|        4|    740|       740|    836|       840|           WN|      311| N504SW|               56|            60|     45|      -4|       0|   HOU| MSY|     303|     3|      8|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1011|      1005|   1116|      1105|           WN|      521| N332SW|               65|            60|     49|      11|       6|   HOU| MSY|     303|     4|     12|        0|            NULL|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2008|    1|         3|        4|   1612|      1520|   1707|      1620|           WN|      714| N305SW|               55|            60|     44|      47|      52|   HOU| MSY|     303|     4|      7|        0|            NULL|       0|           0|           0|       0|            0|               47|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dump the DataFrame to Parquet format\n",
    "flights_subset_df.write.parquet(output_path)\n",
    "\n",
    "\n",
    "# Load the DataFrame back\n",
    "loaded_df = spark.read.parquet(output_path)\n",
    "loaded_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    \"ArrTime\", \"ActualElapsedTime\", \"AirTime\", \"TaxiIn\",\n",
    "    \"Diverted\", \"CarrierDelay\", \"WeatherDelay\", \"NASDelay\",\n",
    "    \"SecurityDelay\", \"LateAircraftDelay\"\n",
    "]\n",
    "\n",
    "flights_df = flights_df.drop(*features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result = (\n",
    "    flights_df\n",
    "    .groupBy(\"Year\", \"Month\")\n",
    "    .agg({\"ArrDelay\": \"avg\", \"DepDelay\": \"avg\", \"Distance\": \"sum\"})\n",
    "    .orderBy(\"Year\", \"Month\")\n",
    ")\n",
    "analysis_result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.printSchema()\n",
    "# flights_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Calculate mean value\n",
    " ###THIS CODE IS FOR REPLACING THE NULL VALUES WITH THE MEAN VALUE OF THE COLUMN\n",
    "# mean_val = flights_df.select(mean(flights_df[TARGET])).collect()[0][0]\n",
    "# flights_df = flights_df.na.fill(mean_val, subset=[TARGET])\n",
    "flights_df = flights_df.withColumn('ArrDelay', flights_df['ArrDelay'].cast(IntegerType()))\n",
    "flights_df = flights_df.withColumn('DepDelay', flights_df['DepDelay'].cast(IntegerType()))\n",
    "\n",
    "# Calculate the mean value of the 'Distance' column\n",
    "mean_distance = flights_df.select(mean(col('Distance'))).collect()[0][0]\n",
    "\n",
    "# Replace all non-numeric values in the 'Distance' column with the mean value\n",
    "flights_df = flights_df.withColumn('Distance', when(col('Distance').cast('integer').isNull(), mean_distance).otherwise(col('Distance').cast('integer')))\n",
    "\n",
    "flights_df.printSchema()\n",
    "#flights_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for Missing Values**: If a column has a high number of missing values, it might not be very useful for prediction. You can check the number of missing values in a column with `df.filter(df[\"column\"].isNull()).count()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Year: 0 (0.00%)\n",
      "Number of missing values in Month: 0 (0.00%)\n",
      "Number of missing values in DayofMonth: 0 (0.00%)\n",
      "Number of missing values in DayOfWeek: 0 (0.00%)\n",
      "Number of missing values in DepTime: 0 (0.00%)\n",
      "Number of missing values in CRSDepTime: 0 (0.00%)\n",
      "Number of missing values in CRSArrTime: 0 (0.00%)\n",
      "Number of missing values in UniqueCarrier: 0 (0.00%)\n",
      "Number of missing values in FlightNum: 0 (0.00%)\n",
      "Number of missing values in TailNum: 0 (0.00%)\n",
      "Number of missing values in CRSElapsedTime: 0 (0.00%)\n",
      "Number of missing values in ArrDelay: 68412 (1.30%)\n",
      "Warning: ArrDelay has at least one missing value , consider dropping those rows or replacing them.\n",
      "Number of missing values in DepDelay: 52458 (1.00%)\n",
      "Warning: DepDelay has at least one missing value , consider dropping those rows or replacing them.\n",
      "Number of missing values in Origin: 0 (0.00%)\n",
      "Number of missing values in Dest: 0 (0.00%)\n",
      "Number of missing values in Distance: 0 (0.00%)\n",
      "Number of missing values in TaxiOut: 0 (0.00%)\n",
      "Number of missing values in Cancelled: 0 (0.00%)\n",
      "Number of missing values in CancellationCode: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "selected_features = []\n",
    "total_rows = flights_df.count()\n",
    "for column in flights_df.columns:\n",
    "    missing_count = flights_df.filter(flights_df[column].isNull()).count()\n",
    "    missing_percentage = (missing_count / total_rows) * 100\n",
    "    print(f\"Number of missing values in {column}: {missing_count} ({missing_percentage:.2f}%)\")\n",
    "    if missing_percentage > 50:\n",
    "        print(f\"Dropping {column} due to high percentage of missing values.\")\n",
    "        flights_df = flights_df.drop(column)\n",
    "    elif missing_percentage > 30:\n",
    "        print(f\"Warning: {column} has more than a 30% of missing values, consider dropping it.\")\n",
    "        selected_features.append(column)\n",
    "    elif missing_count>0:\n",
    "        print(f\"Warning: {column} has at least one missing value , consider dropping those rows or replacing them.\")\n",
    "        selected_features.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.remove('CancellationCode')\n",
    "flights_df = flights_df.drop('CancellationCode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering ArrDelay, type: int\n",
      "Number of rows before filtering: 5270893\n",
      "Number of rows after filtering: 5202481\n",
      "Filtering DepDelay, type: int\n",
      "Number of rows before filtering: 5202481\n",
      "Number of rows after filtering: 5202481\n"
     ]
    }
   ],
   "source": [
    "# filtered_df = flights_df.limit(100000)\n",
    "dtype_dict = dict(flights_df.dtypes)\n",
    "for i in selected_features:\n",
    "    print(f\"Filtering {i}, type: {dtype_dict[i]}\")\n",
    "    # if dtype_dict[i] == IntegerType():\n",
    "    #     print(f\"Number of rows before filtering: {flights_df.count()}\")\n",
    "    #     flights_df = flights_df.filter(col(i).isNotNull() & col(i).cast(\"integer\").isNotNull())\n",
    "    #     print(f\"Number of rows after filtering: {flights_df.count()}\")\n",
    "    print(f\"Number of rows before filtering: {flights_df.count()}\")\n",
    "    flights_df = flights_df.filter(col(i).isNotNull())\n",
    "    print(f\"Number of rows after filtering: {flights_df.count()}\")\n",
    "# flights_df = flights_df.filter(col(TARGET).isNotNull() & col(TARGET).cast(\"integer\").isNotNull())\n",
    "# print(f\"Number of rows after filtering: {flights_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "To decide which variables to drop, you can perform exploratory data analysis (EDA). Here are some steps you can follow:\n",
    "\n",
    "1. **Check for Unique Values**: If a column has a unique value for every row (like an ID), it won't be useful for prediction. You can check the number of distinct values in a column with `df.select(\"column\").distinct().count()`. If the count is equal to the number of rows in your DataFrame, you can drop the column.\n",
    "2. **Check for Constant Values**: If a column has the same value for every row, it also won't be useful for prediction. You can check this with `df.select(\"column\").distinct().count()`. If the count is 1, you can drop the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_rows = flights_df.count()\n",
    "print(f\"Number of rows in the dataframe: {num_of_rows}\")\n",
    "for featur in flights_df.columns:\n",
    "    c1 = flights_df.select(featur).distinct().count() \n",
    "    print(f\"Feature {featur} has {c1} distinct values\")\n",
    "    if c1 == num_of_rows or c1 == 1:\n",
    "        flights_df = flights_df.drop(featur)\n",
    "        print(f\"Feature dropped: {featur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.printSchema()\n",
    "#flights_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#flights_df = flights_df.withColumn('Distance', flights_df['Distance'].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Check for High Correlation**: If two columns are highly correlated, they carry similar information, and you can drop one of them. You can calculate the correlation between two columns with `df.stat.corr(\"column1\", \"column2\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'CRSDepTime',\n",
       " 'CRSArrTime',\n",
       " 'FlightNum',\n",
       " 'CRSElapsedTime',\n",
       " 'ArrDelay',\n",
       " 'DepDelay',\n",
       " 'Distance',\n",
       " 'Cancelled']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_vars = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'CRSArrTime']\n",
    "#create an array of the numerical variables except for time variabes\n",
    "numerical_vars= [item[0] for item in flights_df.dtypes if item[1].startswith('int') | item[1].startswith('double')][1:]\n",
    "#vars = list(set(numerical_vars) - set(time_vars))\n",
    "vars = numerical_vars\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "#vars=numerical_vars\n",
    "for i in range(len(vars)):\n",
    "    for j in range(i+1, len(vars)):\n",
    "        correlation = flights_df.stat.corr(vars[i], vars[j])\n",
    "        if correlation > 0.75 or correlation < -0.75:\n",
    "            print(f\"ATTENTION: Correlation between {vars[i]} and {vars[j]} is too high: {correlation}, consider dropping one of them.\")\n",
    "        else:\n",
    "            print(f\"Correlation between {vars[i]} and {vars[j]}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = feature.VectorAssembler(inputCols=vars,outputCol=\"features\")\n",
    "data = assembler.transform(flights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3639915\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "(train_data, test_data) = data.randomSplit([0.7, 0.3])\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression Model\n",
    "# lr = LinearRegression(featuresCol=\"features\",labelCol=TARGET)\n",
    "# lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RegParam: 0.01\n",
      "Best ElasticNetParam: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Assuming you have 'train_data' as your training dataset and 'TARGET' as the target column\n",
    "# Define the Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=TARGET)\n",
    "\n",
    "# Create a pipeline with the Linear Regression model\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator for regression tasks\n",
    "evaluator = RegressionEvaluator(labelCol=TARGET, metricName=\"rmse\")\n",
    "\n",
    "# Create a CrossValidator with the Linear Regression model, parameter grid, and evaluator\n",
    "cross_validator = CrossValidator(estimator=pipeline,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=evaluator,\n",
    "                                 numFolds=5)  # You can adjust the number of folds as needed\n",
    "\n",
    "# Run cross-validation to find the best model\n",
    "cv_model = cross_validator.fit(train_data)\n",
    "\n",
    "# Get the best model from the cross-validation\n",
    "best_lr_model = cv_model.bestModel.stages[0]\n",
    "\n",
    "# Optionally, you can print the best hyperparameters\n",
    "print(\"Best RegParam:\", best_lr_model.getRegParam())\n",
    "print(\"Best ElasticNetParam:\", best_lr_model.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9996001704832248,0.0,0.0,0.0]\n",
      "Intercept: 0.002723639988620084\n",
      "numIterations: 23\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|0.026064085219204003|\n",
      "|0.010070904548186377|\n",
      "|0.002074314212682893|\n",
      "|0.008871415997859344|\n",
      "|4.749961455816631...|\n",
      "|0.006872268413985694|\n",
      "|0.001274655179132722|\n",
      "|-7.24492404743593E-4|\n",
      "|-0.00472278757249...|\n",
      "|-0.00552244660604...|\n",
      "|-0.00432295805572...|\n",
      "|-3.24662887968507...|\n",
      "|-0.00472278757249...|\n",
      "|-0.00552244660604...|\n",
      "|4.749961455816631...|\n",
      "|-7.24492404743593E-4|\n",
      "|0.002873973246233...|\n",
      "|-0.00272363998862...|\n",
      "|-0.01112005984089...|\n",
      "|0.003273802763008149|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 0.010000178809415262\n",
      "r2: 0.9999998401363576\n"
     ]
    }
   ],
   "source": [
    "# Print model coefficients and intercept\n",
    "print(f\"Coefficients: {best_lr_model.coefficients}\")\n",
    "print(f\"Intercept: {best_lr_model.intercept}\")\n",
    "\n",
    "# Get training summary\n",
    "trainingSummary = best_lr_model.summary\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"numIterations: {trainingSummary.totalIterations}\")\n",
    "trainingSummary.residuals.show()\n",
    "print(f\"RMSE: {trainingSummary.rootMeanSquaredError}\")\n",
    "print(f\"r2: {trainingSummary.r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.00999665\n",
      "Mean Absolute Error (MAE) on test data = 0.00573577\n",
      "R-squared on test data = 1\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "predictions = best_lr_model.transform(test_data)\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"ArrDelay\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)\n",
    "\n",
    "# R-squared\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"R-squared on test data = %g\" % r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9367758b914eda5e9656a2e8cb31fa6c1a33028a9235e34dbffc853c5c7deb38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
