{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2720c580-5cae-4e95-acc8-513899af8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Context with SparkConf\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf()\n",
    "sc = SparkContext.getOrCreate(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd9644-c7c8-41c7-b3df-583e432404c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 1\n",
    "# Add the phone prefix to the numbers using as reference the International Calling Codes\n",
    "# Use a Broadcast Variable\n",
    "\n",
    "input_data = [(\"Simón\",\"Bolivar\",\"VEN\",\"489 895 965\"),\n",
    "    (\"Fidel\",\"Castro\",\"CU\",\"956 268 348\"),\n",
    "    (\"Jose\",\"Doroteo\",\"MEX\",\"985 621 444\"),\n",
    "    (\"Ernesto\",\"Guevara\",\"AR\",\"895 325 481\"),\n",
    "    (\"Hugo\",\"Chávez\",\"VE\",\"489 895 965\"),\n",
    "    (\"Camilo\",\"Cienfuegos\",\"CUB\",\"956 268 348\"),\n",
    "    (\"Andrés Manuel\",\"López\",\"ME\",\"985 621 444\"),\n",
    "    (\"Juan Domingo\",\"Perón\",\"ARG\",\"985 621 444\"),\n",
    "  ]\n",
    "\n",
    "rdd = sc.parallelize(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf29d59-1e03-4100-ac7f-d14c24802e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m result_rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(add_phone_prefix)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Show the result\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m result_data \u001b[38;5;241m=\u001b[39m \u001b[43mresult_rdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m result_data:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(record)\n",
      "File \u001b[1;32mc:\\Users\\mikel\\Desktop\\Master\\BigData\\BigDataPracticalWork\\app\\venv\\Lib\\site-packages\\pyspark\\rdd.py:1833\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1831\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext):\n\u001b[0;32m   1832\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1833\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mPythonRDD\u001b[39m.\u001b[39mcollectAndServe(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jrdd\u001b[39m.\u001b[39mrdd())\n\u001b[0;32m   1834\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32mc:\\Users\\mikel\\Desktop\\Master\\BigData\\BigDataPracticalWork\\app\\venv\\Lib\\site-packages\\pyspark\\rdd.py:5470\u001b[0m, in \u001b[0;36mPipelinedRDD._jrdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5467\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5468\u001b[0m     profiler \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 5470\u001b[0m wrapped_func \u001b[39m=\u001b[39m _wrap_function(\n\u001b[0;32m   5471\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prev_jrdd_deserializer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jrdd_deserializer, profiler\n\u001b[0;32m   5472\u001b[0m )\n\u001b[0;32m   5474\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   5475\u001b[0m python_rdd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mPythonRDD(\n\u001b[0;32m   5476\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prev_jrdd\u001b[39m.\u001b[39mrdd(), wrapped_func, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreservesPartitioning, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_barrier\n\u001b[0;32m   5477\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mikel\\Desktop\\Master\\BigData\\BigDataPracticalWork\\app\\venv\\Lib\\site-packages\\pyspark\\rdd.py:5270\u001b[0m, in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[0;32m   5268\u001b[0m pickled_command, broadcast_vars, env, includes \u001b[39m=\u001b[39m _prepare_for_python_RDD(sc, command)\n\u001b[0;32m   5269\u001b[0m \u001b[39massert\u001b[39;00m sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 5270\u001b[0m \u001b[39mreturn\u001b[39;00m sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mSimplePythonFunction(\n\u001b[0;32m   5271\u001b[0m     \u001b[39mbytearray\u001b[39;49m(pickled_command),\n\u001b[0;32m   5272\u001b[0m     env,\n\u001b[0;32m   5273\u001b[0m     includes,\n\u001b[0;32m   5274\u001b[0m     sc\u001b[39m.\u001b[39;49mpythonExec,\n\u001b[0;32m   5275\u001b[0m     sc\u001b[39m.\u001b[39;49mpythonVer,\n\u001b[0;32m   5276\u001b[0m     broadcast_vars,\n\u001b[0;32m   5277\u001b[0m     sc\u001b[39m.\u001b[39;49m_javaAccumulator,\n\u001b[0;32m   5278\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "# Define the phone prefixes as a dictionary\n",
    "calling_codes = {\n",
    "    \"VEN\": \"+58\",\n",
    "    \"CU\": \"+53\",\n",
    "    \"MEX\": \"+52\",\n",
    "    \"AR\": \"+54\",\n",
    "    \"VE\": \"+58\",\n",
    "    \"CUB\": \"+53\",\n",
    "    \"ME\": \"+52\",\n",
    "    \"ARG\": \"+54\",\n",
    "}\n",
    "\n",
    "# Broadcast the calling codes\n",
    "broadcast_codes = sc.broadcast(calling_codes)\n",
    "\n",
    "# Function to add the phone prefix using the broadcast variable\n",
    "def add_phone_prefix(record):\n",
    "    first_name, last_name, country_code, phone_number = record\n",
    "    prefix = broadcast_codes.value.get(country_code, \"\")\n",
    "    return (first_name, last_name, country_code, prefix + phone_number)\n",
    "\n",
    "# Map the RDD using the broadcast variable\n",
    "result_rdd = rdd.map(add_phone_prefix)\n",
    "\n",
    "# Show the result\n",
    "result_data = result_rdd.collect()\n",
    "for record in result_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8203980-5c79-4ea4-aa71-89116ed64048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 2\n",
    "# Count the number of times the word 'to' appears in a line and the number of lines in the bible.txt file\n",
    "# Use Accumulators\n",
    "\n",
    "input_file_path=\"bible.txt\"\n",
    "rdd = sc.textFile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2cb4bb-b69f-408a-b911-490fb3354c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80da84d3-032d-4a1a-a122-9b15f3b19b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 3\n",
    "# Write the RDD containing the pagecounts dataset \n",
    "# Write the RDD but with only 2 partitions+\n",
    "# Use Repartition\n",
    "\n",
    "input_file_path=\"pagecounts\"\n",
    "rdd = sc.textFile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8aebe-544d-451a-9e60-336ca2670ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f36a976-62ce-491f-887c-76e3f4ddb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 4\n",
    "# Check the differences in computation time when using cache method on an RDD\n",
    "# Read pagecount files and count lines with and without using cache method\n",
    "# show the time differences\n",
    "# Use Cache\n",
    "\n",
    "import time\n",
    "input_file_path=\"pagecounts\"\n",
    "rdd = sc.textFile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51523803-deea-4aaa-b240-47e75bce483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 5\n",
    "# use spark-submit to launch the app.py file by yourself\n",
    "# :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d36129-0b5f-4c19-9f6d-f2f24cb38513",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "690f2f857305324ec80385bbcd0cbcceb9ff9c570252c9b3adda08028153e17a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
